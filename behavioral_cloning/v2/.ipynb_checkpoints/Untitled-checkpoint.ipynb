{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79d9275c-acce-4866-8312-7fc0fa3712b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 18:02:58 - INFO - Using device: cpu\n",
      "2025-04-20 18:02:58 - INFO - --- Starting Card Policy Training (BC) with Memory Efficiency ---\n",
      "2025-04-20 18:03:05 - INFO - Found 35373 total game groups in HDF5 file.\n",
      "2025-04-20 18:03:05 - INFO - Splitting group names for BC (keeping 85% for training)...\n",
      "2025-04-20 18:03:05 - INFO - BC Training groups: 30067, Validation groups: 5306\n",
      "2025-04-20 18:03:05 - INFO - Counting total valid training samples (this might take some time)...\n",
      "2025-04-20 18:03:05 - CRITICAL - Fatal error during valid sample counting: expected one more observations than actions: 1 != 1 + 1. Exiting.\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_272/869903930.py\", line 310, in <module>\n",
      "    _ = next(count_iterator_instance)\n",
      "  File \"/tmp/ipykernel_272/869903930.py\", line 175, in __next__\n",
      "    return types.Trajectory(\n",
      "  File \"<string>\", line 7, in __init__\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/imitation/data/types.py\", line 396, in __post_init__\n",
      "    raise ValueError(\n",
      "ValueError: expected one more observations than actions: 1 != 1 + 1\n",
      "2025-04-20 18:03:05 - INFO - HDF5 file handle closed.\n",
      "2025-04-20 18:03:05 - INFO - Finished counting. Total valid training samples found: 0.\n",
      "2025-04-20 18:03:05 - CRITICAL - No valid training samples found after filtering. Cannot train. Exiting.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected one more observations than actions: 1 != 1 + 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 351\u001b[0m\n\u001b[1;32m    347\u001b[0m rng \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mdefault_rng(RANDOM_SEED)\n\u001b[1;32m    349\u001b[0m \u001b[38;5;66;03m# Note: imitation.BC takes 'demonstrations' which can be an Iterable[Trajectory].\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# It internally wraps this in a DataLoader.\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m bc_trainer \u001b[38;5;241m=\u001b[39m \u001b[43mbc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBC\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobservation_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43maction_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdemonstrations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_demonstrations_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Pass the iterator directly\u001b[39;49;00m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBC_BATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBC_LEARNING_RATE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Use default loss_calculator - should be fine with PyTorch 2+ and recent imitation/SB3\u001b[39;49;00m\n\u001b[1;32m    360\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;66;03m# Calculate total timesteps based on epochs and total valid samples\u001b[39;00m\n\u001b[1;32m    363\u001b[0m total_timesteps \u001b[38;5;241m=\u001b[39m total_training_samples \u001b[38;5;241m*\u001b[39m BC_N_EPOCHS\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/imitation/algorithms/bc.py:330\u001b[0m, in \u001b[0;36mBC.__init__\u001b[0;34m(self, observation_space, action_space, rng, policy, demonstrations, batch_size, minibatch_size, optimizer_cls, optimizer_kwargs, ent_weight, l2_weight, device, custom_logger)\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminibatch_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch size must be a multiple of minibatch size.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 330\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdemonstrations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdemonstrations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_logger\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_logger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bc_logger \u001b[38;5;241m=\u001b[39m BCLogger(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space \u001b[38;5;241m=\u001b[39m action_space\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/imitation/algorithms/base.py:164\u001b[0m, in \u001b[0;36mDemonstrationAlgorithm.__init__\u001b[0;34m(self, demonstrations, custom_logger, allow_variable_horizon)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    159\u001b[0m     custom_logger\u001b[38;5;241m=\u001b[39mcustom_logger,\n\u001b[1;32m    160\u001b[0m     allow_variable_horizon\u001b[38;5;241m=\u001b[39mallow_variable_horizon,\n\u001b[1;32m    161\u001b[0m )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m demonstrations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_demonstrations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdemonstrations\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/imitation/algorithms/bc.py:376\u001b[0m, in \u001b[0;36mBC.set_demonstrations\u001b[0;34m(self, demonstrations)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_demonstrations\u001b[39m(\u001b[38;5;28mself\u001b[39m, demonstrations: algo_base\u001b[38;5;241m.\u001b[39mAnyTransitions) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_demo_data_loader \u001b[38;5;241m=\u001b[39m \u001b[43malgo_base\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_data_loader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdemonstrations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminibatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/imitation/algorithms/base.py:258\u001b[0m, in \u001b[0;36mmake_data_loader\u001b[0;34m(transitions, batch_size, data_loader_kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be positive.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(transitions, Iterable):\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;66;03m# Inferring the correct type here is difficult with generics.\u001b[39;00m\n\u001b[1;32m    255\u001b[0m     (\n\u001b[1;32m    256\u001b[0m         first_item,\n\u001b[1;32m    257\u001b[0m         transitions,\n\u001b[0;32m--> 258\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_first_iter_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[assignment]\u001b[39;49;00m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_item, types\u001b[38;5;241m.\u001b[39mTrajectory):\n\u001b[1;32m    262\u001b[0m         transitions \u001b[38;5;241m=\u001b[39m cast(Iterable[types\u001b[38;5;241m.\u001b[39mTrajectory], transitions)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/imitation/util/util.py:358\u001b[0m, in \u001b[0;36mget_first_iter_element\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    356\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(iterable)\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 358\u001b[0m     first_element \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miterable \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miterable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m had no elements to iterate over.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 175\u001b[0m, in \u001b[0;36mHDF5CardDemoIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m     action_int64 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([action_index], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# Return as a Trajectory of length 1\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;66;03m# Corrected: Removed 'next_obs' and replaced 'dones' with 'terminal'\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrajectory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobs_float32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Shape (1, INPUT_DIM) float32\u001b[39;49;00m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43macts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction_int64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Shape (1,) int64\u001b[39;49;00m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43minfos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Shape (1,)\u001b[39;49;00m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mterminal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Assuming these state-action pairs are not terminal steps in an episode context for BC\u001b[39;49;00m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;66;03m# Invalid sample (card not found in hand), continue loop to find the next one\u001b[39;00m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# The sample index was already incremented above, so next __next__ will try the next sample\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m<string>:7\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, obs, acts, infos, terminal)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/imitation/data/types.py:396\u001b[0m, in \u001b[0;36mTrajectory.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Performs input validation: check shapes are as specified in docstring.\"\"\"\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macts) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 396\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    397\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected one more observations than actions: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m + 1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    399\u001b[0m     )\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfos) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macts):\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfos when present must be present for each action: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfos)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    404\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: expected one more observations than actions: 1 != 1 + 1"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "train_card_policy_bc.py\n",
    "\n",
    "Trains a card prediction policy using Behavioral Cloning (BC)\n",
    "based on data parsed into an HDF5 file.\n",
    "\n",
    "Assumes the HDF5 file contains 'state_bits' (bool, N x 929) and\n",
    "'action_card_bits' (bool, N x 13) datasets, as generated by the parser.\n",
    "Converts action_card_bits to action_index (int, N) during loading.\n",
    "\n",
    "Uses the standard imitation.algorithms.bc.BC trainer.\n",
    "Requires compatible versions of torch, gymnasium, stable-baselines3, and imitation.\n",
    "\"\"\"\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "# stable_baselines3 is implicitly used by imitation for policy structure\n",
    "import stable_baselines3 as sb3\n",
    "# Import core BC algorithm and data types\n",
    "from imitation.algorithms import bc\n",
    "from imitation.data import types\n",
    "# No need for TrainingMetrics or util imports here when using default loss_calculator\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import torch as th # Use th alias for torch conventions\n",
    "import traceback # To print full error tracebacks\n",
    "from typing import Tuple, Optional\n",
    "from sklearn.model_selection import train_test_split # Corrected import\n",
    "\n",
    "\n",
    "# --- Logging Configuration ---\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    datefmt='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "HDF5_FILE_PATH = r'../../../Training_Data/jass.hdf5'  # <--- Path to the HDF5 file from your parser\n",
    "POLICY_SAVE_PATH = 'jass_bc_card_policy_591' # Model save path\n",
    "\n",
    "# --- Data Keys (Must match your parser's output HDF5 structure) ---\n",
    "OBS_KEY = 'state_bits'          # N x 929 boolean array\n",
    "ACTION_BITS_KEY = 'action_card_bits' # N x 13 boolean array (the played card's representation)\n",
    "\n",
    "# --- Model Dimensions (Based on your parser) ---\n",
    "INPUT_DIM = 929 # From your parser's STATE_BITS calculation\n",
    "CARD_ACTION_DIM = 9 # 9 possible card positions in hand (index 0-8)\n",
    "\n",
    "# --- Constants from Parser (Needed to interpret state_bits) ---\n",
    "CARD_BITS = 13 # Bits used to represent a single card in the parser\n",
    "NUM_CARDS_HISTORY = 32 # Number of history card slots in state (32 * 13 bits)\n",
    "NUM_CARDS_TABLE = 3  # Number of table card slots in state (3 * 13 bits) - matches parser code, not comment\n",
    "NUM_CARDS_HAND = 9   # Number of hand card slots in state (9 * 13 bits) - matches CARD_ACTION_DIM conceptually\n",
    "\n",
    "# Calculate the starting index of the player's hand bits within the state_bits vector\n",
    "# Order from parser: History, Table, Hand, Shown, Trump\n",
    "HAND_START_BIT_INDEX = (NUM_CARDS_HISTORY * CARD_BITS) + (NUM_CARDS_TABLE * CARD_BITS)\n",
    "# 32 * 13 = 416\n",
    "# 3 * 13  = 39\n",
    "# HAND_START_BIT_INDEX = 416 + 39 = 455. The hand bits are from index 455 up to 455 + (9*13) = 455 + 117 = 572.\n",
    "\n",
    "# --- Training Hyperparameters ---\n",
    "VALIDATION_SPLIT_SIZE = 0.15 # Use 15% of data for validation (optional for BC eval)\n",
    "RANDOM_SEED = 42 # For reproducible train/test splits\n",
    "BC_BATCH_SIZE = 32\n",
    "BC_LEARNING_RATE = 3e-4\n",
    "BC_N_EPOCHS = 10 # Number of passes over the training data\n",
    "\n",
    "device = th.device(\"cpu\")\n",
    "logging.info(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "# --- 1. Load Data Function (Kept Action Conversion) ---\n",
    "def load_bc_data_from_hdf5(filepath: str) -> Tuple[Optional[np.ndarray], Optional[np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Loads observations and converts action card bits (N x 13 bool) to action indices (N x 1 int, 0-8)\n",
    "    by finding the index of the played card within the hand representation in the state.\n",
    "    Loads data from all groups in the HDF5 file.\n",
    "    \"\"\"\n",
    "    all_obs = []\n",
    "    all_action_indices = [] # Store the derived action indices (0-8)\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        logging.error(f\"HDF5 file not found at: {filepath}\")\n",
    "        return None, None\n",
    "\n",
    "    try:\n",
    "        with h5py.File(filepath, 'r') as f:\n",
    "            # Load data from a subset of groups for speed if needed, or all\n",
    "            #game_groups = list(f.keys()) # Load all groups\n",
    "            game_groups = list(f.keys())[:5000] # Example: Load only first 2000 games for faster testing\n",
    "            logging.info(f\"Found {len(game_groups)} game groups in HDF5 file for BC.\")\n",
    "\n",
    "            if not game_groups:\n",
    "                logging.error(\"No game groups found in the HDF5 file.\")\n",
    "                return None, None\n",
    "\n",
    "            for i, group_name in enumerate(game_groups):\n",
    "                if (i + 1) % 100 == 0:\n",
    "                    logging.info(f\"Loading and processing group {i+1}/{len(game_groups)} for BC: {group_name}\")\n",
    "                try:\n",
    "                    group = f[group_name]\n",
    "                    # --- Check required keys ---\n",
    "                    if OBS_KEY not in group:\n",
    "                        logging.warning(f\"BC Skipping group '{group_name}': Missing dataset '{OBS_KEY}'\")\n",
    "                        continue\n",
    "                    # We now expect 'action_card_bits' from the parser\n",
    "                    if ACTION_BITS_KEY not in group:\n",
    "                        logging.error(f\"BC CRITICAL: Skipping group '{group_name}': Missing dataset '{ACTION_BITS_KEY}'.\")\n",
    "                        logging.error(f\"Ensure your parser saves the 13-bit card representation as '{ACTION_BITS_KEY}'.\")\n",
    "                        continue # Skip group if critical action data is missing\n",
    "\n",
    "                    obs_group_data = group[OBS_KEY][:] # Shape (N, INPUT_DIM) bool -> N x 929\n",
    "                    actions_bits_group_data = group[ACTION_BITS_KEY][:] # Shape (N, CARD_BITS) bool -> N x 13\n",
    "\n",
    "                    # --- Basic Validation ---\n",
    "                    if obs_group_data.shape[0] != actions_bits_group_data.shape[0]:\n",
    "                        logging.warning(f\"BC Skipping group '{group_name}': Data length mismatch ({obs_group_data.shape[0]} vs {actions_bits_group_data.shape[0]}).\")\n",
    "                        continue\n",
    "                    if obs_group_data.shape[0] == 0:\n",
    "                         logging.info(f\"BC Skipping empty group '{group_name}'.\")\n",
    "                         continue\n",
    "                    if obs_group_data.shape[1] != INPUT_DIM:\n",
    "                        logging.warning(f\"BC Skipping group '{group_name}': Observation dimension mismatch (Expected {INPUT_DIM}, Got {obs_group_data.shape[1]}).\")\n",
    "                        continue\n",
    "                    # Validate the shape of the action bits data from the parser\n",
    "                    if actions_bits_group_data.shape[1] != CARD_BITS:\n",
    "                         logging.warning(f\"BC Skipping group '{group_name}': Action bits dimension mismatch (Expected {CARD_BITS}, Got {actions_bits_group_data.shape[1]}).\")\n",
    "                         continue\n",
    "\n",
    "                    # --- Convert Action Card Bits to Action Index (0-8) ---\n",
    "                    # Iterate through each state-action pair in the group\n",
    "                    group_derived_indices = []\n",
    "                    # Convert boolean arrays to integers (0 or 1) for easier comparison/processing\n",
    "                    # This conversion is safe as boolean True/False become 1/0\n",
    "                    obs_group_int = obs_group_data.astype(np.int8)\n",
    "                    actions_bits_group_int = actions_bits_group_data.astype(np.int8)\n",
    "\n",
    "                    for j in range(obs_group_int.shape[0]):\n",
    "                        state_vec_int = obs_group_int[j, :] # This sample's state (929 integers 0/1)\n",
    "                        played_card_bits_int = actions_bits_group_int[j, :] # This sample's action card bits (13 integers 0/1)\n",
    "\n",
    "                        # Extract the player's hand bits from the state vector\n",
    "                        # Hand bits start at HAND_START_BIT_INDEX and are NUM_CARDS_HAND * CARD_BITS long\n",
    "                        hand_bits_int = state_vec_int[HAND_START_BIT_INDEX : HAND_START_BIT_INDEX + NUM_CARDS_HAND * CARD_BITS]\n",
    "\n",
    "                        # Find the index of the played_card_bits within the hand_bits\n",
    "                        action_index = -1 # Default to not found\n",
    "                        for card_idx_in_hand in range(NUM_CARDS_HAND):\n",
    "                            # Extract the bits for the current card in the hand\n",
    "                            start_idx = card_idx_in_hand * CARD_BITS\n",
    "                            end_idx = start_idx + CARD_BITS\n",
    "                            current_hand_card_bits_int = hand_bits_int[start_idx : end_idx]\n",
    "\n",
    "                            # Compare the played card bits with the current hand card bits\n",
    "                            # Use np.array_equal for a robust comparison of the 13-element vectors\n",
    "                            if np.array_equal(played_card_bits_int, current_hand_card_bits_int):\n",
    "                                action_index = card_idx_in_hand # Found the index!\n",
    "                                break # Found the card in hand, its index is our action\n",
    "\n",
    "                        if action_index == -1:\n",
    "                            # This indicates a problem: the card recorded as played was not found in the state's hand\n",
    "                            # (e.g., due to parsing errors, inconsistent state/action logging)\n",
    "                            # We skip this sample as we cannot determine the correct action index (0-8)\n",
    "                            # from the player's perspective at that state.\n",
    "                            # You could log the bit sequences for debugging if this happens often.\n",
    "                            # logging.warning(f\"BC WARNING: Card played (bits: {played_card_bits_int.tolist()}) not found in hand (bits: {hand_bits_int.reshape(-1, CARD_BITS).tolist()}) for sample {j} in group '{group_name}'. Skipping this sample.\")\n",
    "                            continue # Skip to the next sample (j)\n",
    "\n",
    "                        # If index was found (0-8), append it\n",
    "                        group_derived_indices.append(action_index)\n",
    "\n",
    "                    # Only append data from this group if we successfully derived at least one index\n",
    "                    if group_derived_indices:\n",
    "                        # Convert boolean observations to float32 for the model\n",
    "                        all_obs.append(obs_group_data.astype(np.float32)) # Use original boolean data for obs -> float32\n",
    "                        # Append the derived action indices for the samples that were not skipped\n",
    "                        all_action_indices.append(np.array(group_derived_indices, dtype=np.int64)) # Ensure actions are int64\n",
    "                    else:\n",
    "                         logging.warning(f\"BC: No valid action indices derived for group '{group_name}'. Skipping entire group.\")\n",
    "\n",
    "\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"BC Error processing group '{group_name}': {e}\")\n",
    "                    traceback.print_exc() # Print traceback for detailed error\n",
    "                    continue # Skip this group on error\n",
    "\n",
    "            if not all_obs or not all_action_indices:\n",
    "                logging.error(\"BC: No valid data loaded from any group.\")\n",
    "                return None, None\n",
    "\n",
    "            # Concatenate data from all groups\n",
    "            logging.info(\"BC: Concatenating data from all groups...\")\n",
    "            final_obs = np.concatenate(all_obs, axis=0)\n",
    "            final_action_indices = np.concatenate(all_action_indices, axis=0)\n",
    "            logging.info(\"BC: Concatenation complete.\")\n",
    "            logging.info(f\"Final concatenated data shapes: obs={final_obs.shape}, actions={final_action_indices.shape}\")\n",
    "\n",
    "\n",
    "            # Final sanity check on action indices range (should be 0-8)\n",
    "            # np.max and np.min will error on empty arrays, check size first\n",
    "            if final_action_indices.size > 0:\n",
    "                if np.max(final_action_indices) >= CARD_ACTION_DIM or np.min(final_action_indices) < 0:\n",
    "                     logging.error(f\"BC CRITICAL: Derived action indices out of range (0-{CARD_ACTION_DIM-1}). Max: {np.max(final_action_indices)}, Min: {np.min(final_action_indices)}\")\n",
    "                     # This indicates a major issue in the derivation logic or source data\n",
    "                     # You might want to raise an error or filter these out explicitly if they exist\n",
    "                     pass # Allow continuation for now, but investigate data if this warning appears often\n",
    "            else:\n",
    "                 logging.warning(\"No action indices were derived after loading and filtering data.\")\n",
    "\n",
    "\n",
    "            return final_obs, final_action_indices\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.critical(f\"BC: Failed to load data from HDF5 file '{filepath}': {e}\")\n",
    "        traceback.print_exc() # Print traceback for detailed error\n",
    "        return None, None\n",
    "\n",
    "\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    logging.info(\"--- Starting Card Policy Training (BC) ---\")\n",
    "\n",
    "    # --- Load Data ---\n",
    "    # We now expect the second return value to be the action indices (0-8)\n",
    "    observations, card_action_indices = load_bc_data_from_hdf5(HDF5_FILE_PATH)\n",
    "\n",
    "    if observations is None or card_action_indices is None:\n",
    "        logging.critical(\"Could not load data for BC training. Exiting.\")\n",
    "        exit()\n",
    "    # Ensure observations and action indices have the same number of samples after loading and filtering\n",
    "    if len(observations) != len(card_action_indices):\n",
    "         logging.critical(f\"Observation and action index counts mismatch after loading: {len(observations)} vs {len(card_action_indices)}. Exiting.\")\n",
    "         exit()\n",
    "    if len(observations) == 0:\n",
    "         logging.critical(\"No valid data samples loaded for BC training. Exiting.\")\n",
    "         exit()\n",
    "    logging.info(f\"Total valid data samples loaded for BC: {len(observations)}.\")\n",
    "\n",
    "\n",
    "    # --- Split Data (Optional for BC, but good practice) ---\n",
    "    logging.info(f\"Splitting data for BC (keeping {1-VALIDATION_SPLIT_SIZE:.0%} for training)...\")\n",
    "    # We primarily need the training split for BC demonstrations\n",
    "    # Ensure both obs and action_indices are split together\n",
    "    obs_train, obs_val, act_train_indices, act_val_indices = train_test_split(\n",
    "        observations, card_action_indices, # Use the derived indices here\n",
    "        test_size=VALIDATION_SPLIT_SIZE,\n",
    "        random_state=RANDOM_SEED,\n",
    "        shuffle=True,\n",
    "        # stratify=card_action_indices # Optional: Stratify to ensure action distribution is similar in train/val splits - requires all indices to be valid (0-8). Uncomment if needed and all data is valid.\n",
    "    )\n",
    "    logging.info(f\"BC Training samples: {len(obs_train)}, Validation samples: {len(obs_val)}\")\n",
    "    # Free up memory from the original full arrays and validation splits\n",
    "    del observations, card_action_indices, obs_val, act_val_indices\n",
    "\n",
    "\n",
    "    # --- Prepare Data & Spaces for Imitation Library ---\n",
    "    # The Transitions object holds NumPy arrays. The batching logic in bc.train\n",
    "    # will convert these to tensors and move them to the device using its internal\n",
    "    # mechanism (e.g., safe_to_tensor).\n",
    "    dummy_next_obs_array = np.zeros_like(obs_train)\n",
    "\n",
    "    train_demonstrations = types.Transitions(\n",
    "        obs=obs_train, # NumPy array\n",
    "        acts=act_train_indices, # NumPy array of integer indices (0-8)\n",
    "        infos=np.array([None] * len(obs_train), dtype=object), # Dummy infos (NumPy array)\n",
    "        next_obs=dummy_next_obs_array, # Dummy next_obs (NumPy array)\n",
    "        dones=np.array([False] * len(obs_train)), # Dummy dones (NumPy array)\n",
    "    )\n",
    "    # Free up memory from the arrays now held by the Transitions object\n",
    "    del obs_train, act_train_indices\n",
    "\n",
    "\n",
    "    observation_space = gym.spaces.Box(low=0, high=1, shape=(INPUT_DIM,), dtype=np.float32)\n",
    "    action_space = gym.spaces.Discrete(CARD_ACTION_DIM) # Keep Discrete(9) for action index\n",
    "\n",
    "\n",
    "    # --- Train Behavioral Cloning Model ---\n",
    "    rng = np.random.default_rng(RANDOM_SEED)\n",
    "    bc_trainer = bc.BC(\n",
    "        observation_space=observation_space,\n",
    "        action_space=action_space,\n",
    "        demonstrations=train_demonstrations, # Pass the Transitions object (with NumPy arrays)\n",
    "        batch_size=BC_BATCH_SIZE,\n",
    "        optimizer_kwargs=dict(lr=BC_LEARNING_RATE),\n",
    "        device=device, # Ensure the trainer/policy are created on the correct device\n",
    "        rng=rng,\n",
    "        # *** USING DEFAULT loss_calculator ***\n",
    "        # If you encounter the device RuntimeError again, it means the default\n",
    "        # loss_calculator in your imitation version has the bug.\n",
    "        # In that case, you would need to use the minimalist custom loss calculator\n",
    "        # code from the previous response, which should work if torch and numpy are available.\n",
    "        # loss_calculator=CorrectedBehaviorCloningLossCalculator() # Uncomment if device bug persists with default\n",
    "    )\n",
    "\n",
    "    # Calculate n_batches based on the total number of training samples\n",
    "    n_batches_per_epoch = len(train_demonstrations.obs) // BC_BATCH_SIZE\n",
    "    if len(train_demonstrations.obs) % BC_BATCH_SIZE != 0:\n",
    "        n_batches_per_epoch += 1 # Account for the last partial batch\n",
    "\n",
    "    n_batches = n_batches_per_epoch * BC_N_EPOCHS\n",
    "    # Ensure n_batches is at least 1 if there's data\n",
    "    n_batches = max(1, n_batches) if len(train_demonstrations.obs) > 0 else 0\n",
    "\n",
    "\n",
    "    logging.info(f\"Starting BC training for {BC_N_EPOCHS} epochs (~{n_batches_per_epoch} batches per epoch) totaling {n_batches} batches...\")\n",
    "    if n_batches > 0:\n",
    "        # Using n_batches argument which is compatible with many imitation versions\n",
    "        # Adjust log_interval based on the total number of batches\n",
    "        bc_trainer.train(n_batches=n_batches, log_interval=max(1, n_batches // 50)) # Log more frequently, e.g., 50 times per training run\n",
    "    else:\n",
    "        logging.warning(\"No training batches available. Skipping training.\")\n",
    "\n",
    "\n",
    "    # --- Save Policy ---\n",
    "    if n_batches > 0: # Only attempt to save if training actually ran\n",
    "        try:\n",
    "            # The policy object is stored in bc_trainer.policy\n",
    "            # Save it using the underlying SB3 policy save method\n",
    "            # This saves an SB3-compatible policy, usually as a .zip file\n",
    "            bc_trainer.policy.save(f\"{POLICY_SAVE_PATH}.zip\")\n",
    "            logging.info(f\"Card prediction policy saved successfully to {POLICY_SAVE_PATH}.zip\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error saving BC policy: {e}\")\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        logging.warning(\"Skipping policy save because no training was performed.\")\n",
    "\n",
    "\n",
    "    logging.info(\"--- Card Policy Training Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847d3eea-a123-4af3-a1ac-ff6b32e0aadb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
